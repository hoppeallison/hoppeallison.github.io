---
layout: post
title: Project 2 Predicting Price of 1 bedroom apartment
---

The topic of our second project was linear regression. For this project we were able to choose our own topics. I decided to try and predict the rent of a 1 bedroom apartment.  I was interested in whether a model could predict the price of a 1 bedroom apartment from other cost of living and demographic features. 

The data set I used for the analysis included prices of various items including eggs, milk, water, cappuccino, apples, train ticket, movie tickets and utilities. It also included a grocery index, restaurant index and local purchasing power index (relative to NYC). This data set included information for around 120 cities in the US. I combined this data set with median household income and population density data from the US Census website. 

At first I included all of the variables in the linear regression model fit. However, the model was overfitting when comparing the R^2 value on the training set of data compared to the validation set. I could tell that the model was overfitting since the R^2 value was higher on the training set than the validation set and there was a large difference between the two R^2 values. In order to reduce the overfitting of the model I used regularization. Regularization constrains the coefficients in a narrower region in order to produce a more stable less extreme model.  I first used LASSO regression, also known as least absolute shrinkage and selection operator, which is useful for feature selection. As the regularization strength parameter increases, the coefficients for each feature move towards zero. LASSO regression first drops the features that are less useful in predicting the target, leaving the features that are most significant in predicting the target. 

![Graph 1](/images/LARSpath.png)

After using LASSO regression for feature selection, I also used Ridge regression. This is another type of regularization that dampens the feature coefficients but keeps all of the features instead of dropping the least predictive features. Using both of these types of regularization led to R^2 values that were closer together between the training and validation sets. Using cross validation there was still some variation in training and validation R^2 values between some of the cuts. I felt the size of my data set could be leading to this variation. Using a larger data set in the future would most likely reduce the overfitting and variation issues.

Ultimately, the model features that were associated with the cost of a 1 bedroom apartment were the median household income, population density, price of eggs, price of a movie ticket and the restaurant price index relative to NYC.

Finally, I tested the model using recent parameters for the city of Chicago. The model predicted the price of a 1 bedroom apartment in Chicago to be $1,970.50 compared to an actual price of $1,888.83.



